{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Forecasting income per person</center>\n## <center>Testing_Model and Metrics</center>\n## Authors:\n### >>> Alex Samoylenko\n### >>> Vladyslav Honcharuk\n### >>> Ostap Kalapun'\n### >>> Maksym Chernykh","metadata":{}},{"cell_type":"markdown","source":"## Algorithm","metadata":{}},{"cell_type":"code","source":"# in case of removing errors\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.279366Z","iopub.execute_input":"2022-09-11T20:58:29.279830Z","iopub.status.idle":"2022-09-11T20:58:29.308340Z","shell.execute_reply.started":"2022-09-11T20:58:29.279737Z","shell.execute_reply":"2022-09-11T20:58:29.307519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test.drop('target_full_ltv_day30', axis=1)\ny_test = test.target_full_ltv_day30","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.310590Z","iopub.execute_input":"2022-09-11T20:58:29.311660Z","iopub.status.idle":"2022-09-11T20:58:29.382104Z","shell.execute_reply.started":"2022-09-11T20:58:29.311621Z","shell.execute_reply":"2022-09-11T20:58:29.380115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.drop('Unnamed: 0', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.383472Z","iopub.status.idle":"2022-09-11T20:58:29.383943Z","shell.execute_reply.started":"2022-09-11T20:58:29.383742Z","shell.execute_reply":"2022-09-11T20:58:29.383761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing model","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_percentage_error","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.385291Z","iopub.status.idle":"2022-09-11T20:58:29.385863Z","shell.execute_reply.started":"2022-09-11T20:58:29.385581Z","shell.execute_reply":"2022-09-11T20:58:29.385607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nmodel_lgb = pickle.load(open('model_lgb.sav', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.387690Z","iopub.status.idle":"2022-09-11T20:58:29.388240Z","shell.execute_reply.started":"2022-09-11T20:58:29.387952Z","shell.execute_reply":"2022-09-11T20:58:29.387977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_lgb.predict(X_test)\nscore_mae = mean_absolute_error(y_test, predictions)\nscore_mape = mean_absolute_percentage_error(y_test, predictions)\nscore_rmse = mean_squared_error(y_test, predictions, squared=False)\nprint(\"LightGBM\")\nprint(\"MAE score:\", score_mae)\nprint(\"MAPE score:\", score_mape)\nprint(\"RMSE score:\", score_rmse)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T20:58:29.389569Z","iopub.status.idle":"2022-09-11T20:58:29.390112Z","shell.execute_reply.started":"2022-09-11T20:58:29.389836Z","shell.execute_reply":"2022-09-11T20:58:29.389862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Back to top](#Index)\n\n## Metrics\n\nThe championship organizers urged us to demonstrate the model accuracy on these 3 aforementioned metrics. However, one of the metrics is not appliable to this dataset at all. That is a MAPE metrics. MAPE has target value in the formula's denominator that causes, in this case, zero division as most of the target values are either zero or infinitesimally small, which is technically zero.\n\nThen we have RMSE metrics that performed overall good, and showed relative consistency after every model accuracy test. We mean 'relative' because RMSE metrics enhances any outliers influence, which we certainly have in this dataset.\n\nFinally, we have oriented on a MAE metrics the most. MAE didn't really have any of the cons we mentioned in this conclusion.","metadata":{}}]}